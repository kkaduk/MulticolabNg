pekko {
  loglevel = INFO
  
  actor {
    provider = cluster
    
    serialization-bindings {
      "net.kaduk.domain.Message" = jackson-json
    }
  }
  
  http {
    server {
      preview.enable-http2 = on
      default-http-port = 8080
    }
  }
  
  remote.artery {
    canonical.hostname = "127.0.0.1"
    canonical.port = 2556
  }
  
  cluster {
    seed-nodes = ["pekko://AgentSystem@127.0.0.1:2556"]
    downing-provider-class = "org.apache.pekko.cluster.sbr.SplitBrainResolverProvider"
  }
}

agents {
  llm-providers {
    openai {
      api-key = ${?OPENAI_API_KEY}
      model = "gpt-4"
      max-tokens = 2000
      temperature = 0.7
    }
    claude {
      api-key = ${?ANTHROPIC_API_KEY}
      model = "claude-3-5-sonnet-20240620"
    }
    vertex {
      project-id = ${?GCP_PROJECT_ID}
      api-key = ${?VERTEX_API_KEY}
      location = "us-central1"
      model = "gemini-1.5-flash-001"
    }
    ollama {
      base-url = "http://localhost:11434/v1/"
      model = "llama3"
      api-key = ""
    }
  }
  
  agents {
    coordinator {
      type = coordinator
    }
    sql-agent {
      type = llm
      provider = openai
      system-prompt = "You are an SQL expert"
    }
    viz-agent {
      type = llm
      provider = claude
      system-prompt = "You create data visualizations"
    }
  }
}
